sample_size:
  desc: Max number of points
  value: 2000
n_flow_layers:
  desc: Number of flow layers
  value: 20
data_loader:
  desc: What loader to use
  value: ConditionalDataGridCircle
batchnorm:
  desc: batchnorm between flow layers
  value: true
flow_type:
  desc: What flow blocks to use
  value: exponential_coupling
hidden_dims:
  desc: linear layers for flow coupling
  value: [512,512,512,512,512,512]
permuter_type:
  desc: 'How to permute between coupling blocks'
  value: random_permute
early_stop_margin:
  desc: early_stop_margin
  value: 0.0003
count_bins:
  desc: bins for spline
  value: 64
input_dim:
  desc: Dimension of pointcloud data
  value: 6
grid_square_size:
  desc: Number of f subblocks 
  value: 2
clearance:
  desc: clearance
  value: 28
subsample:
  desc: How to subsample
  value: 'fps'
patience:
  desc: patience
  value: 1000
preload:
  desc: Preload_dataset
  value: true
min_points:
  desc: Minimum sample size
  value: 2000
n_epochs:
  desc: Number of epochs to train for
  value: 10000
batch_size:
  desc: Batch size
  value: 30 #35
lr:
  desc: Initial learning rate for optimizer
  value: 0.0001
save_model_path:
  desc: Where to save models (before wandb upload)
  value: save/conditional_flow_compare/
num_workers:
  desc: num_workers
  value: 2
optimizer_type:
  desc: optimizer type
  value: AdamW
weight_decay:
  desc: weigth decay for optimizer
  value: 0.001
data_parallel:
  desc: Use parallel
  value: false
coupling_block_nonlinearity:
  desc: coupling_block_nonlinearity
  value: ELU
min_lr:
  desc: Minimum schedules learning rate
  value: 0.0001
normalization:
  desc: How pairs are normalized
  value: co_unit_sphere
load_checkpoint:
  desc: Path to checkpoint or false for new training
  value: save/conditional_flow_compare/smart-elevator-1246_53_186_model_dict.pt
preselected_points:
  desc: Use preselected points
  value: true
dirs_challenge_csv:
  desc: Paths to label csv folder
  value: save/2016-2020-train/
attn_dim:
  desc: Dimension of cross attention embedding fed to coupling block MLP
  value: 100
input_embedding_dim:
  desc: Dimension of input embeddings, part of input for attention
  value: 256
cross_heads:
  desc: Number of attn heads
  value: 1
cross_dim_head:
  desc: Dimension of cross dim head
  value: 64
attn_dropout:
  desc: Dropout rate in attn module
  value: 0.0
